{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 诗data的地址\n",
    "poetry_data_path = \"./data/poetry.txt\"\n",
    "# 如果诗词中出现这些词，则将诗舍弃\n",
    "DISALLOWED_WORDS = ['（', '）', '(', ')', '__', '《', '》', '【', '】', '[', ']']\n",
    "# 取3000个字作诗,其中包括空格字符\n",
    "WORD_NUM = 3000\n",
    "# 将出现少的字使用空格代替\n",
    "UNKONW_CHAR = \" \"\n",
    "# 根据前6个字预测下一个字，比如说根据“寒随穷律变，”预测“春”\n",
    "TRAIN_NUM = 6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 保存诗词\n",
    "poetrys = []\n",
    "# 保存在诗词中出现的字\n",
    "all_word = []\n",
    "\n",
    "with open(poetry_data_path,encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        # 获得诗的内容\n",
    "        poetry = line.split(\":\")[1].replace(\" \",\"\")\n",
    "        flag = True\n",
    "        # 如果在句子中出现'（', '）', '(', ')', '__', '《', '》', '【', '】', '[', ']'则舍弃\n",
    "        for dis_word in DISALLOWED_WORDS:\n",
    "            if dis_word in poetry:\n",
    "                flag = False\n",
    "                break\n",
    "\n",
    "        # 只需要5言的诗（两句诗包括标点符号就是12个字），假如少于两句诗则舍弃\n",
    "        if  len(poetry) < 12 or poetry[5] != '，' or (len(poetry)-1) % 6 != 0:\n",
    "            flag = False\n",
    "\n",
    "        if flag:\n",
    "            # 统计出现的词\n",
    "            for word in poetry:\n",
    "                all_word.append(word)\n",
    "            poetrys.append(poetry)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print(\"一共有：{}首诗，一共有{}个字符\".format(len(poetrys),len(all_word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# 对字数进行统计\n",
    "counter = Counter(all_word)\n",
    "# 根据出现的次数，进行从大到小的排序\n",
    "word_count = sorted(counter.items(),key=lambda x : -x[1])\n",
    "most_num_word,_ = zip(*word_count)\n",
    "# 取前2999个字，然后在最后加上\" \"\n",
    "use_words = most_num_word[:WORD_NUM - 1] + (UNKONW_CHAR,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "source": [
    "print(use_words[-20:])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word 到 id的映射 {'，': 0,'。': 1,'\\n': 2,'不': 3,'人': 4,'山': 5,……}\n",
    "word_id_dict = {word:index for index,word in enumerate(use_words)}\n",
    "\n",
    "# id 到 word的映射 {0: '，',1: '。',2: '\\n',3: '不',4: '人',5: '山',……}\n",
    "id_word_dict = {index:word for index,word in enumerate(use_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(list(word_id_dict.items())[0:10])\n",
    "print(list(id_word_dict.items())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def word_to_one_hot(word):\n",
    "    \"\"\"将一个字转成onehot形式\n",
    "\n",
    "    :param word: [一个字]\n",
    "    :type word: [str]\n",
    "    \"\"\"\n",
    "    one_hot_word = np.zeros(WORD_NUM)\n",
    "    # 假如字是生僻字，则变成空格\n",
    "    if word not in word_id_dict.keys():\n",
    "        word = UNKONW_CHAR\n",
    "    index = word_id_dict[word]\n",
    "    one_hot_word[index] = 1\n",
    "    return one_hot_word\n",
    "\n",
    "def phrase_to_one_hot(phrase):\n",
    "    \"\"\"将一个句子转成onehot\n",
    "\n",
    "    :param phrase: [一个句子]\n",
    "    :type poetry: [str]\n",
    "    \"\"\"\n",
    "    one_hot_phrase = []\n",
    "    for word in phrase:\n",
    "        one_hot_phrase.append(word_to_one_hot(word))\n",
    "    return one_hot_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_one_hot(\"，\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_to_one_hot(\"，。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(poetrys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_word = []\n",
    "Y_train_word = []\n",
    "\n",
    "for poetry in poetrys:\n",
    "    for i in range(len(poetry)):\n",
    "        X = poetry[i:i+TRAIN_NUM]\n",
    "        Y = poetry[i+TRAIN_NUM]\n",
    "        if \"\\n\" not in X and \"\\n\" not in Y:\n",
    "            X_train_word.append(X)\n",
    "            Y_train_word.append(Y)\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_word[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.callbacks import LambdaCallback,ModelCheckpoint\n",
    "from keras.models import Input, Model\n",
    "from keras.layers import  Dropout, Dense,SimpleRNN \n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "\n",
    "def build_model():\n",
    "    print('building model')\n",
    "    # 输入的dimension\n",
    "    input_tensor = Input(shape=(TRAIN_NUM,WORD_NUM))\n",
    "    rnn = SimpleRNN(512,return_sequences=True)(input_tensor)\n",
    "    dropout = Dropout(0.6)(rnn)\n",
    "\n",
    "    rnn = SimpleRNN(256)(dropout)\n",
    "    dropout = Dropout(0.6)(rnn)\n",
    "    dense = Dense(WORD_NUM, activation='softmax')(dropout)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=dense)\n",
    "    optimizer = Adam(lr=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    # 画出模型图\n",
    "    # plot_model(model, to_file='model.png', show_shapes=True, expand_nested=True, dpi=500)\n",
    "    return  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_batch(batch_size = 32):\n",
    "    \"\"\"源源不断产生产生one-hot编码的训练数据\n",
    "\n",
    "    :param batch_size: [一次产生训练数据的大小], defaults to 32\n",
    "    :type batch_size: int, optional\n",
    "    :yield: [返回X（np.array(X_train_batch)）和Y（np.array(Y_train_batch)）]\n",
    "    :rtype: [X.shape为(batch_size, 6, 3000) , Y.shape数据的shape(batch_size, 3000)]\n",
    "    \"\"\"\n",
    "    # 确定每轮有多少个batch\n",
    "    steps = math.ceil(len(X_train_word) / batch_size)\n",
    "    while True:\n",
    "        for i in range(steps):\n",
    "            X_train_batch = []\n",
    "            Y_train_batch = []\n",
    "            X_batch_datas = X_train_word[i*batch_size:(i+1)*batch_size]\n",
    "            Y_batch_datas = Y_train_word[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "            for x,y in zip(X_batch_datas,Y_batch_datas):\n",
    "                X_train_batch.append(phrase_to_one_hot(x))\n",
    "                Y_train_batch.append(word_to_one_hot(y))\n",
    "            yield np.array(X_train_batch),np.array(Y_train_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next(x):\n",
    "    \"\"\" 根据X预测下一个字符\n",
    "\n",
    "    :param x: [输入数据]\n",
    "    :type x: [x的shape为(1,TRAIN_NUM,WORD_NUM)]\n",
    "    :return: [最大概率字符的索引，有可能为为2999，也就是预测的字符可能为“ ”]\n",
    "    :rtype: [int]\n",
    "    \"\"\"\n",
    "    predict_y = model.predict(x)[0]\n",
    "    # 获得最大概率的索引\n",
    "    index = np.argmax(predict_y)\n",
    "    return index\n",
    "\n",
    "def generate_sample_result(epoch, logs):\n",
    "    \"\"\"生成五言诗\n",
    "\n",
    "    :param epoch: [目前模型训练的epoch]\n",
    "    :type epoch: [int]\n",
    "    :param logs: [模型训练日志]\n",
    "    :type logs: [list]\n",
    "    \"\"\"\n",
    "    # 每个epoch都产生输出\n",
    "    if epoch % 1 == 0:\n",
    "        predict_sen = \"一朝春夏改，\"\n",
    "        predict_data = predict_sen\n",
    "        # 生成的4句五言诗（4 * 6 = 24）\n",
    "        while len(predict_sen) < 24:\n",
    "            X_data = np.array(phrase_to_one_hot(predict_data)).reshape(1,TRAIN_NUM,WORD_NUM)\n",
    "            # 根据6个字符预测下一个字符\n",
    "            y = predict_next(X_data)\n",
    "            predict_sen = predict_sen+ id_word_dict[y]\n",
    "            # “寒随穷律变，” ——> “随穷律变，春”\n",
    "            predict_data = predict_data[1:]+id_word_dict[y]\n",
    "        # 将数据写入文件    \n",
    "        with open('out/out.txt', 'a',encoding='utf-8') as f:\n",
    "            f.write(write_data+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2048\n",
    "model.fit_generator(\n",
    "            generator=get_batch(batch_size),\n",
    "            verbose=True,\n",
    "            steps_per_epoch=math.ceil(len(X_train_word) / batch_size),\n",
    "            epochs=30,\n",
    "            callbacks=[\n",
    "                ModelCheckpoint(\"poetry_model.hdf5\",verbose=1,monitor='val_loss',period=1),\n",
    "                # 每次完成一个epoch会调用generate_sample_result产生五言诗\n",
    "                LambdaCallback(on_epoch_end=generate_sample_result)\n",
    "            ]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}